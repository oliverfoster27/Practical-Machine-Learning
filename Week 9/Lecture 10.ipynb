{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learning to act in complex environments\n",
    "- Maximize some reward in a complex environment\n",
    "- Actions done by the agent influences the environment it exists in\n",
    "- Continue until \"termination\" where you finally measure how rewarded you are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is this difficult?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No immediate label\n",
    "- Reward is from a combination of actions\n",
    "- I need to determine what part of my actions generated the reward\n",
    "- I need to explore the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Value Network: Regression problem that estimates the reward of your current state\n",
    "- Policy Network: decides your moves for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discount Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The discount rate indicates that future rewards is worth less than short-term rewards\n",
    "    - Analogy: interest rates indicate that the same money in the future is worth less\n",
    "- Discount rate modulates your preference for short-term reward or long-term reward and what your preferred tradeoff is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the policy that has the greatest expected returns\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Value\n",
    "- The expected return for a given move if you continue with your policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "- If you wanted to do this without deep learning you could just hard-code your policy & run the algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-AI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gym) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.0 in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gym) (2.21.0)\n",
      "Requirement already satisfied: six in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gym) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gym) (1.16.2)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.0->gym) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.0->gym) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.0->gym) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.0->gym) (2019.3.9)\n",
      "Requirement already satisfied: future in c:\\users\\olive\\appdata\\local\\continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from pyglet>=1.2.0->gym) (0.17.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Function\n",
    "This function determines where you should try to go given your current position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(obs):\n",
    "    \"\"\"\n",
    "    Up = 3\n",
    "    Right = 2\n",
    "    Down = 1\n",
    "    Left = 0\n",
    "    Hole = -1 (reset board)\n",
    "    Goal = -2 (you win)\n",
    "    \"\"\"\n",
    "    mapping = [\n",
    "         2,  2, 1,  0,\n",
    "         1, -1, 1, -1,\n",
    "         2,  1, 1, -1,\n",
    "        -1,  2, 2, -2\n",
    "    ]\n",
    "    return mapping[obs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the environment making movements depending on your policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FH\u001b[41mF\u001b[0mH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "\u001b[41mH\u001b[0mFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "\u001b[41mH\u001b[0mFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "\u001b[41mH\u001b[0mFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Left)\n",
      "SFFF\n",
      "FHF\u001b[41mH\u001b[0m\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "\u001b[41mH\u001b[0mFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "\u001b[41mH\u001b[0mFFG\n",
      "Reward: 0.0\n",
      "You fell in the hole\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FH\u001b[41mF\u001b[0mH\n",
      "FFFH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "Reward: 0.0\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "Reward: 0.0\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "Reward: 1.0\n",
      "You win!\n",
      "Number of moves: 71\n",
      "Number of deaths: 16\n"
     ]
    }
   ],
   "source": [
    "# Watch out - slippage can happen that messes up your movement\n",
    "env = gym.make('FrozenLake-v0')\n",
    "obs = env.reset()\n",
    "epochs = 0\n",
    "deaths = 0\n",
    "\n",
    "env.render()\n",
    "\n",
    "while (True):\n",
    "    \n",
    "    direction = policy(obs)\n",
    "    if direction == -1:\n",
    "        print(\"You fell in the hole\")\n",
    "        deaths += 1\n",
    "        obs = env.reset()\n",
    "        continue\n",
    "    elif direction == -2:\n",
    "        print(\"You win!\")\n",
    "        break\n",
    "    obs, reward, is_done, info = env.step(direction)\n",
    "    env.render()\n",
    "    print(\"Reward: {}\".format(reward))\n",
    "    epochs += 1\n",
    "    \n",
    "print(\"Number of moves: {}\".format(epochs))\n",
    "print(\"Number of deaths: {}\".format(deaths))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
