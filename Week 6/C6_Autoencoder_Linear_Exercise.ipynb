{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C6 Autoencoder Linear Exercise.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverfoster27/Practical-Machine-Learning/blob/master/Week%206/C6_Autoencoder_Linear_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K5VI-l7e6c9M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0KYN8VNb6mkR",
        "colab_type": "code",
        "outputId": "422705d1-1811-43eb-ad1a-501087dc155d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/nicksdemobucket/anonymized_data.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-13 14:17:01--  https://storage.googleapis.com/nicksdemobucket/anonymized_data.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 284033 (277K) [application/octet-stream]\n",
            "Saving to: ‘anonymized_data.csv’\n",
            "\n",
            "\ranonymized_data.csv   0%[                    ]       0  --.-KB/s               \ranonymized_data.csv 100%[===================>] 277.38K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2019-04-13 14:17:02 (96.2 MB/s) - ‘anonymized_data.csv’ saved [284033/284033]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "orIzchym6w0W",
        "colab_type": "code",
        "outputId": "ab63beff-c8ea-4e0d-853a-13937cf0a199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('anonymized_data.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EJWY</th>\n",
              "      <th>VALM</th>\n",
              "      <th>EGXO</th>\n",
              "      <th>HTGR</th>\n",
              "      <th>SKRF</th>\n",
              "      <th>NNSZ</th>\n",
              "      <th>NYLC</th>\n",
              "      <th>GWID</th>\n",
              "      <th>TVUT</th>\n",
              "      <th>CJHI</th>\n",
              "      <th>...</th>\n",
              "      <th>LKKS</th>\n",
              "      <th>UOBF</th>\n",
              "      <th>VBHE</th>\n",
              "      <th>FRWU</th>\n",
              "      <th>NDYZ</th>\n",
              "      <th>QSBO</th>\n",
              "      <th>JDUB</th>\n",
              "      <th>TEVK</th>\n",
              "      <th>EZTM</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.032145</td>\n",
              "      <td>1.019576</td>\n",
              "      <td>-9.658715</td>\n",
              "      <td>-6.210495</td>\n",
              "      <td>3.156823</td>\n",
              "      <td>7.457850</td>\n",
              "      <td>-5.313357</td>\n",
              "      <td>8.508296</td>\n",
              "      <td>3.959194</td>\n",
              "      <td>-5.246654</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.209663</td>\n",
              "      <td>-10.340123</td>\n",
              "      <td>-7.697555</td>\n",
              "      <td>-5.932752</td>\n",
              "      <td>10.872688</td>\n",
              "      <td>0.081321</td>\n",
              "      <td>1.276316</td>\n",
              "      <td>5.281225</td>\n",
              "      <td>-0.516447</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.306217</td>\n",
              "      <td>6.649376</td>\n",
              "      <td>-0.960333</td>\n",
              "      <td>-4.094799</td>\n",
              "      <td>8.738965</td>\n",
              "      <td>-3.458797</td>\n",
              "      <td>7.016800</td>\n",
              "      <td>6.692765</td>\n",
              "      <td>0.898264</td>\n",
              "      <td>9.337643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.851793</td>\n",
              "      <td>-9.678324</td>\n",
              "      <td>-6.071795</td>\n",
              "      <td>1.428194</td>\n",
              "      <td>-8.082792</td>\n",
              "      <td>-0.557089</td>\n",
              "      <td>-7.817282</td>\n",
              "      <td>-8.686722</td>\n",
              "      <td>-6.953100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.570842</td>\n",
              "      <td>6.985462</td>\n",
              "      <td>-1.842621</td>\n",
              "      <td>-1.569599</td>\n",
              "      <td>10.039339</td>\n",
              "      <td>-3.623026</td>\n",
              "      <td>8.957619</td>\n",
              "      <td>7.577283</td>\n",
              "      <td>1.541255</td>\n",
              "      <td>7.161509</td>\n",
              "      <td>...</td>\n",
              "      <td>1.376085</td>\n",
              "      <td>-8.971164</td>\n",
              "      <td>-5.302191</td>\n",
              "      <td>2.898965</td>\n",
              "      <td>-8.746597</td>\n",
              "      <td>-0.520888</td>\n",
              "      <td>-7.350999</td>\n",
              "      <td>-8.925501</td>\n",
              "      <td>-7.051179</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.139972</td>\n",
              "      <td>0.579422</td>\n",
              "      <td>-9.526530</td>\n",
              "      <td>-5.744928</td>\n",
              "      <td>4.834355</td>\n",
              "      <td>5.907235</td>\n",
              "      <td>-4.804137</td>\n",
              "      <td>6.798810</td>\n",
              "      <td>5.403670</td>\n",
              "      <td>-7.642857</td>\n",
              "      <td>...</td>\n",
              "      <td>0.270571</td>\n",
              "      <td>-8.640988</td>\n",
              "      <td>-8.105419</td>\n",
              "      <td>-5.079015</td>\n",
              "      <td>9.351282</td>\n",
              "      <td>0.641759</td>\n",
              "      <td>1.898083</td>\n",
              "      <td>3.904671</td>\n",
              "      <td>1.453499</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.738104</td>\n",
              "      <td>0.234729</td>\n",
              "      <td>-11.558768</td>\n",
              "      <td>-7.181332</td>\n",
              "      <td>4.189626</td>\n",
              "      <td>7.765274</td>\n",
              "      <td>-2.189083</td>\n",
              "      <td>7.239925</td>\n",
              "      <td>3.135602</td>\n",
              "      <td>-6.211390</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013973</td>\n",
              "      <td>-9.437110</td>\n",
              "      <td>-6.475267</td>\n",
              "      <td>-5.708377</td>\n",
              "      <td>9.623080</td>\n",
              "      <td>1.802899</td>\n",
              "      <td>1.903705</td>\n",
              "      <td>4.188442</td>\n",
              "      <td>1.522362</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       EJWY      VALM       EGXO      HTGR       SKRF      NNSZ      NYLC  \\\n",
              "0 -2.032145  1.019576  -9.658715 -6.210495   3.156823  7.457850 -5.313357   \n",
              "1  8.306217  6.649376  -0.960333 -4.094799   8.738965 -3.458797  7.016800   \n",
              "2  6.570842  6.985462  -1.842621 -1.569599  10.039339 -3.623026  8.957619   \n",
              "3 -1.139972  0.579422  -9.526530 -5.744928   4.834355  5.907235 -4.804137   \n",
              "4 -1.738104  0.234729 -11.558768 -7.181332   4.189626  7.765274 -2.189083   \n",
              "\n",
              "       GWID      TVUT      CJHI  ...        LKKS       UOBF      VBHE  \\\n",
              "0  8.508296  3.959194 -5.246654  ...   -2.209663 -10.340123 -7.697555   \n",
              "1  6.692765  0.898264  9.337643  ...    0.851793  -9.678324 -6.071795   \n",
              "2  7.577283  1.541255  7.161509  ...    1.376085  -8.971164 -5.302191   \n",
              "3  6.798810  5.403670 -7.642857  ...    0.270571  -8.640988 -8.105419   \n",
              "4  7.239925  3.135602 -6.211390  ...   -0.013973  -9.437110 -6.475267   \n",
              "\n",
              "       FRWU       NDYZ      QSBO      JDUB      TEVK      EZTM  Label  \n",
              "0 -5.932752  10.872688  0.081321  1.276316  5.281225 -0.516447    0.0  \n",
              "1  1.428194  -8.082792 -0.557089 -7.817282 -8.686722 -6.953100    1.0  \n",
              "2  2.898965  -8.746597 -0.520888 -7.350999 -8.925501 -7.051179    1.0  \n",
              "3 -5.079015   9.351282  0.641759  1.898083  3.904671  1.453499    0.0  \n",
              "4 -5.708377   9.623080  1.802899  1.903705  4.188442  1.522362    0.0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "2R8oPwvh64C2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df.drop(['Label'], axis=1)\n",
        "y = df['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7boh87SEE5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b262ea2-4c84-4f83-ea6d-f516ccfb424c"
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "eA_qUAfYD5zk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVwOq_nID7QW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7193
        },
        "outputId": "6fdc03b6-f6eb-4ea9-e381-73fc05c172a8"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30, activation=\"linear\", input_shape=(30,)))\n",
        "model.add(Dense(2, activation=\"linear\", name='compressed'))\n",
        "model.add(Dense(30, activation=\"linear\"))\n",
        "\n",
        "model.compile('adam', 'mse')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(X, X, epochs=200, batch_size=100, verbose=1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "compressed (Dense)           (None, 2)                 62        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 30)                90        \n",
            "=================================================================\n",
            "Total params: 1,082\n",
            "Trainable params: 1,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "500/500 [==============================] - 1s 1ms/sample - loss: 39.1648\n",
            "Epoch 2/200\n",
            "500/500 [==============================] - 0s 32us/sample - loss: 34.9198\n",
            "Epoch 3/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 32.8205\n",
            "Epoch 4/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 32.0001\n",
            "Epoch 5/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 31.7752\n",
            "Epoch 6/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 31.6008\n",
            "Epoch 7/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 31.2576\n",
            "Epoch 8/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 30.8188\n",
            "Epoch 9/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 30.4012\n",
            "Epoch 10/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 30.0155\n",
            "Epoch 11/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 29.6455\n",
            "Epoch 12/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 29.2619\n",
            "Epoch 13/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 28.8553\n",
            "Epoch 14/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 28.4351\n",
            "Epoch 15/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 28.0130\n",
            "Epoch 16/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 27.5837\n",
            "Epoch 17/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 27.1468\n",
            "Epoch 18/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 26.7061\n",
            "Epoch 19/200\n",
            "500/500 [==============================] - 0s 20us/sample - loss: 26.2601\n",
            "Epoch 20/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 25.8164\n",
            "Epoch 21/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 25.3580\n",
            "Epoch 22/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 24.9062\n",
            "Epoch 23/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 24.4509\n",
            "Epoch 24/200\n",
            "500/500 [==============================] - 0s 20us/sample - loss: 24.0078\n",
            "Epoch 25/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 23.5653\n",
            "Epoch 26/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 23.1263\n",
            "Epoch 27/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 22.6836\n",
            "Epoch 28/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 22.2578\n",
            "Epoch 29/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 21.8312\n",
            "Epoch 30/200\n",
            "500/500 [==============================] - 0s 20us/sample - loss: 21.4088\n",
            "Epoch 31/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 20.9964\n",
            "Epoch 32/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 20.5854\n",
            "Epoch 33/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 20.1833\n",
            "Epoch 34/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 19.7843\n",
            "Epoch 35/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 19.3915\n",
            "Epoch 36/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 19.0008\n",
            "Epoch 37/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 18.6125\n",
            "Epoch 38/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 18.2284\n",
            "Epoch 39/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 17.8462\n",
            "Epoch 40/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 17.4646\n",
            "Epoch 41/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 17.0838\n",
            "Epoch 42/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 16.7040\n",
            "Epoch 43/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 16.3241\n",
            "Epoch 44/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 15.9440\n",
            "Epoch 45/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 15.5626\n",
            "Epoch 46/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 15.1823\n",
            "Epoch 47/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 14.8003\n",
            "Epoch 48/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 14.4168\n",
            "Epoch 49/200\n",
            "500/500 [==============================] - 0s 33us/sample - loss: 14.0352\n",
            "Epoch 50/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 13.6608\n",
            "Epoch 51/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 13.2764\n",
            "Epoch 52/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 12.8942\n",
            "Epoch 53/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 12.5184\n",
            "Epoch 54/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 12.1414\n",
            "Epoch 55/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 11.7725\n",
            "Epoch 56/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 11.4083\n",
            "Epoch 57/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 11.0363\n",
            "Epoch 58/200\n",
            "500/500 [==============================] - 0s 33us/sample - loss: 10.6763\n",
            "Epoch 59/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 10.3200\n",
            "Epoch 60/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 9.9738\n",
            "Epoch 61/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 9.6296\n",
            "Epoch 62/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 9.2955\n",
            "Epoch 63/200\n",
            "500/500 [==============================] - 0s 33us/sample - loss: 8.9619\n",
            "Epoch 64/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 8.6387\n",
            "Epoch 65/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 8.3210\n",
            "Epoch 66/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 8.0058\n",
            "Epoch 67/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 7.7069\n",
            "Epoch 68/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 7.4063\n",
            "Epoch 69/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 7.1156\n",
            "Epoch 70/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 6.8326\n",
            "Epoch 71/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 6.5553\n",
            "Epoch 72/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 6.2870\n",
            "Epoch 73/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 6.0240\n",
            "Epoch 74/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 5.7683\n",
            "Epoch 75/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 5.5220\n",
            "Epoch 76/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 5.2773\n",
            "Epoch 77/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 5.0414\n",
            "Epoch 78/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 4.8188\n",
            "Epoch 79/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 4.5972\n",
            "Epoch 80/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 4.3829\n",
            "Epoch 81/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 4.1765\n",
            "Epoch 82/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 3.9772\n",
            "Epoch 83/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 3.7868\n",
            "Epoch 84/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 3.6033\n",
            "Epoch 85/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 3.4262\n",
            "Epoch 86/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 3.2564\n",
            "Epoch 87/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 3.0932\n",
            "Epoch 88/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 2.9415\n",
            "Epoch 89/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 2.7947\n",
            "Epoch 90/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 2.6561\n",
            "Epoch 91/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 2.5236\n",
            "Epoch 92/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 2.4000\n",
            "Epoch 93/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 2.2818\n",
            "Epoch 94/200\n",
            "500/500 [==============================] - 0s 39us/sample - loss: 2.1729\n",
            "Epoch 95/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 2.0686\n",
            "Epoch 96/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 1.9717\n",
            "Epoch 97/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 1.8823\n",
            "Epoch 98/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 1.7989\n",
            "Epoch 99/200\n",
            "500/500 [==============================] - 0s 37us/sample - loss: 1.7212\n",
            "Epoch 100/200\n",
            "500/500 [==============================] - 0s 32us/sample - loss: 1.6498\n",
            "Epoch 101/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 1.5836\n",
            "Epoch 102/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 1.5231\n",
            "Epoch 103/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 1.4671\n",
            "Epoch 104/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 1.4163\n",
            "Epoch 105/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 1.3699\n",
            "Epoch 106/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 1.3275\n",
            "Epoch 107/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 1.2892\n",
            "Epoch 108/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 1.2546\n",
            "Epoch 109/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 1.2232\n",
            "Epoch 110/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 1.1947\n",
            "Epoch 111/200\n",
            "500/500 [==============================] - 0s 32us/sample - loss: 1.1692\n",
            "Epoch 112/200\n",
            "500/500 [==============================] - 0s 34us/sample - loss: 1.1462\n",
            "Epoch 113/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 1.1254\n",
            "Epoch 114/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 1.1070\n",
            "Epoch 115/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 1.0905\n",
            "Epoch 116/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 1.0757\n",
            "Epoch 117/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 1.0623\n",
            "Epoch 118/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 1.0506\n",
            "Epoch 119/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 1.0402\n",
            "Epoch 120/200\n",
            "500/500 [==============================] - 0s 32us/sample - loss: 1.0306\n",
            "Epoch 121/200\n",
            "500/500 [==============================] - 0s 20us/sample - loss: 1.0222\n",
            "Epoch 122/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 1.0147\n",
            "Epoch 123/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 1.0081\n",
            "Epoch 124/200\n",
            "500/500 [==============================] - 0s 33us/sample - loss: 1.0023\n",
            "Epoch 125/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 0.9971\n",
            "Epoch 126/200\n",
            "500/500 [==============================] - 0s 38us/sample - loss: 0.9923\n",
            "Epoch 127/200\n",
            "500/500 [==============================] - 0s 31us/sample - loss: 0.9881\n",
            "Epoch 128/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 0.9843\n",
            "Epoch 129/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9811\n",
            "Epoch 130/200\n",
            "500/500 [==============================] - 0s 33us/sample - loss: 0.9781\n",
            "Epoch 131/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 0.9755\n",
            "Epoch 132/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 0.9730\n",
            "Epoch 133/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 0.9709\n",
            "Epoch 134/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9691\n",
            "Epoch 135/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9673\n",
            "Epoch 136/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 0.9658\n",
            "Epoch 137/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9645\n",
            "Epoch 138/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 0.9632\n",
            "Epoch 139/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9623\n",
            "Epoch 140/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9612\n",
            "Epoch 141/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 0.9602\n",
            "Epoch 142/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 0.9594\n",
            "Epoch 143/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 0.9587\n",
            "Epoch 144/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9581\n",
            "Epoch 145/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 0.9575\n",
            "Epoch 146/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 0.9569\n",
            "Epoch 147/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 0.9564\n",
            "Epoch 148/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9559\n",
            "Epoch 149/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9555\n",
            "Epoch 150/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9551\n",
            "Epoch 151/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9548\n",
            "Epoch 152/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9544\n",
            "Epoch 153/200\n",
            "500/500 [==============================] - 0s 34us/sample - loss: 0.9541\n",
            "Epoch 154/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9538\n",
            "Epoch 155/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 0.9536\n",
            "Epoch 156/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 0.9533\n",
            "Epoch 157/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9531\n",
            "Epoch 158/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9528\n",
            "Epoch 159/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9526\n",
            "Epoch 160/200\n",
            "500/500 [==============================] - 0s 20us/sample - loss: 0.9524\n",
            "Epoch 161/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9522\n",
            "Epoch 162/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9520\n",
            "Epoch 163/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9518\n",
            "Epoch 164/200\n",
            "500/500 [==============================] - 0s 25us/sample - loss: 0.9517\n",
            "Epoch 165/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 0.9515\n",
            "Epoch 166/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 0.9514\n",
            "Epoch 167/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 0.9513\n",
            "Epoch 168/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 0.9511\n",
            "Epoch 169/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9510\n",
            "Epoch 170/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9508\n",
            "Epoch 171/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 0.9507\n",
            "Epoch 172/200\n",
            "500/500 [==============================] - 0s 30us/sample - loss: 0.9506\n",
            "Epoch 173/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 0.9505\n",
            "Epoch 174/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9504\n",
            "Epoch 175/200\n",
            "500/500 [==============================] - 0s 35us/sample - loss: 0.9503\n",
            "Epoch 176/200\n",
            "500/500 [==============================] - 0s 29us/sample - loss: 0.9502\n",
            "Epoch 177/200\n",
            "500/500 [==============================] - 0s 36us/sample - loss: 0.9501\n",
            "Epoch 178/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9500\n",
            "Epoch 179/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 0.9499\n",
            "Epoch 180/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 0.9497\n",
            "Epoch 181/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9497\n",
            "Epoch 182/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 0.9496\n",
            "Epoch 183/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9495\n",
            "Epoch 184/200\n",
            "500/500 [==============================] - 0s 23us/sample - loss: 0.9494\n",
            "Epoch 185/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9493\n",
            "Epoch 186/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 0.9492\n",
            "Epoch 187/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9492\n",
            "Epoch 188/200\n",
            "500/500 [==============================] - 0s 22us/sample - loss: 0.9491\n",
            "Epoch 189/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 0.9490\n",
            "Epoch 190/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9490\n",
            "Epoch 191/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9489\n",
            "Epoch 192/200\n",
            "500/500 [==============================] - 0s 21us/sample - loss: 0.9489\n",
            "Epoch 193/200\n",
            "500/500 [==============================] - 0s 31us/sample - loss: 0.9488\n",
            "Epoch 194/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9487\n",
            "Epoch 195/200\n",
            "500/500 [==============================] - 0s 28us/sample - loss: 0.9485\n",
            "Epoch 196/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 0.9485\n",
            "Epoch 197/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9485\n",
            "Epoch 198/200\n",
            "500/500 [==============================] - 0s 26us/sample - loss: 0.9484\n",
            "Epoch 199/200\n",
            "500/500 [==============================] - 0s 27us/sample - loss: 0.9484\n",
            "Epoch 200/200\n",
            "500/500 [==============================] - 0s 24us/sample - loss: 0.9483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b47edf3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "S5xVqDGNES6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_compressed_output = Model(inputs=model.inputs, \n",
        "                                outputs=model.get_layer('compressed').output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XeTmbGaTEV-Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "out_compressed = model_compressed_output.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XMtMn7b6Ee4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "85cf1ee8-2abc-42b2-8ed4-f1bdbf0a9b4b"
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(out_compressed[:,0], out_compressed[:,1], c=y)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f1b47cd0128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCT0/+gUcZK0LpT1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "N75fDjkTFI8b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cmL_S7ayFSud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}